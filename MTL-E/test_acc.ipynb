{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pushpak/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence = [\n",
    "    \"I hate Muslim terrorists and the psychotic Muslims in ISIS. Is that allowed in your politically correct version of reality?\",\n",
    "    \"Apparently the emails state he buys meth from gay Islamic party boys who are transphobic hate blacks puppies and illegally voted for Hillary\",\n",
    "    \"None of that would ever have happened if he werent black. What do you mean?\",\n",
    "    \"1000000 women are just idiots? Your simpleminded generalization paints you as seeming to be one too\"\n",
    "]\n",
    "\n",
    "label = [1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which model are you testing\n",
    "model_name = \"bert-large-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, task_name):\n",
    "    # Load the configuration\n",
    "    config_path = f\"{task_name}_model/{model_name}/config.json\"\n",
    "    config = transformers.AutoConfig.from_pretrained(config_path)\n",
    "\n",
    "    # Load the model state dict\n",
    "    model_path = f\"{task_name}_model/{model_name}/pytorch_model.bin\"\n",
    "    model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "        pretrained_model_name_or_path=None,\n",
    "        config=config,\n",
    "        state_dict=torch.load(model_path)\n",
    "    )\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(f\"{task_name}_model/{model_name}\")\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load test data from CSV\n",
    "def load_test_data(csv_path):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, test_data, task_name, batch_size=8):\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    sentences = []\n",
    "    \n",
    "    for i in range(0, len(test_data), batch_size):\n",
    "        batch_data = test_data.iloc[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_data['Sentence'].tolist(), max_length=128, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        labels = torch.tensor(batch_data['labels'].tolist())\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        true_list.extend(labels.cpu().numpy())\n",
    "        pred_list.extend(predictions)\n",
    "        sentences.extend(batch_data['Sentence'].tolist())\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    conf_matrix = confusion_matrix(true_list, pred_list)\n",
    "    class_report = classification_report(true_list, pred_list, output_dict=True)\n",
    "    df_data = {\n",
    "        \"Sentence\": sentences,\n",
    "        \"True\": true_list,\n",
    "        \"Predicted\": pred_list\n",
    "    }\n",
    "    df = pd.DataFrame(df_data)\n",
    "    df.to_csv(f\"{task_name}_results.csv\", index=False)\n",
    "    return conf_matrix, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3145826/1288519749.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict=torch.load(model_path)\n",
      "/tmp/ipykernel_3145826/1288519749.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict=torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Sentence  identity_attack_x  \\\n",
      "0     As someone pointed out earlier ISIS and radic...           0.800000   \n",
      "1     URL bellamycharlottesvilletwitter  Read up on...           0.506024   \n",
      "2    . . .  she wants to give other women of color ...           0.500000   \n",
      "3    . The whole world hates the white world yet th...           0.500000   \n",
      "4    ... what horrible human beings .... pathetic. ...           0.653333   \n",
      "..                                                 ...                ...   \n",
      "645  Youre right he should pick something else to b...           0.500000   \n",
      "646  Youre right the international condemnation of ...           0.700000   \n",
      "647  Youre the one making claims.  I called you on ...           0.600000   \n",
      "648  Youre white so clearly you dont understand or ...           0.800000   \n",
      "649  Yup I keep telling people people like you are ...           0.636364   \n",
      "\n",
      "     labels          target       category  \\\n",
      "0         1  muslims,whites  religion,race   \n",
      "1         0             NaN           none   \n",
      "2         1          whites    race,gender   \n",
      "3         1          whites           race   \n",
      "4         1      christians       religion   \n",
      "..      ...             ...            ...   \n",
      "645       1          whites           race   \n",
      "646       1            jews       religion   \n",
      "647       1            gays          lgbtq   \n",
      "648       1          whites           race   \n",
      "649       1          blacks           race   \n",
      "\n",
      "                                rationale   id  \n",
      "0    prejudice against whites and muslims    1  \n",
      "1                                     NaN    2  \n",
      "2             prejudice against white men    3  \n",
      "3                prejudice against whites    4  \n",
      "4            prejudice against christians    5  \n",
      "..                                    ...  ...  \n",
      "645              prejudice against whites  646  \n",
      "646                prejudice against jews  647  \n",
      "647                prejudice towards gays  648  \n",
      "648              prejudice against whites  649  \n",
      "649              prejudice against blacks  650  \n",
      "\n",
      "[650 rows x 7 columns]\n",
      "Evaluating bias model...\n",
      "---------------------------------Confusion Matrix------------------------------------\n",
      "    0    1\n",
      "0  43   88\n",
      "1  54  465\n",
      "---------------------------------Evaluation Metrics------------------------------------\n",
      "              precision    recall  f1-score     support\n",
      "0              0.443299  0.328244  0.377193  131.000000\n",
      "1              0.840868  0.895954  0.867537  519.000000\n",
      "accuracy       0.781538  0.781538  0.781538    0.781538\n",
      "macro avg      0.642083  0.612099  0.622365  650.000000\n",
      "weighted avg   0.760743  0.781538  0.768714  650.000000\n",
      "Results saved to ./results/bias_bert-large-uncased_results.csv\n",
      "                                               Sentence  labels    id\n",
      "0                             She hailed Mother Russia.       1     1\n",
      "1     The mover will be here soon. They don't really...       1     2\n",
      "2     He was being hateful to the server and demandi...       1     3\n",
      "3     In TLC's 90 DAY FIANCE one of the couples was ...       1     4\n",
      "4                   He wore pants that showed his crack       1     5\n",
      "...                                                 ...     ...   ...\n",
      "1694            She was very understanding and flexible       0  1695\n",
      "1695  Sometimes the girls bickered and sniped at eac...       1  1696\n",
      "1696  I'm thinking of going to Somalia. Everyone the...       1  1697\n",
      "1697  The Ukrainian professor taught philosophy at t...       1  1698\n",
      "1698  He cooks dinner for his grandchildren once a w...       0  1699\n",
      "\n",
      "[1699 rows x 3 columns]\n",
      "Evaluating stereotype model...\n",
      "---------------------------------Confusion Matrix------------------------------------\n",
      "     0    1\n",
      "0  723   85\n",
      "1  114  777\n",
      "---------------------------------Evaluation Metrics------------------------------------\n",
      "              precision    recall  f1-score      support\n",
      "0              0.863799  0.894802  0.879027   808.000000\n",
      "1              0.901392  0.872054  0.886480   891.000000\n",
      "accuracy       0.882872  0.882872  0.882872     0.882872\n",
      "macro avg      0.882596  0.883428  0.882754  1699.000000\n",
      "weighted avg   0.883514  0.882872  0.882936  1699.000000\n",
      "Results saved to ./results/stereotype_bert-large-uncased_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "bias_model, bias_tokenizer = load_model(model_name, \"bias\")\n",
    "stereotype_model, stereotype_tokenizer = load_model(model_name, \"stereotype\")\n",
    "\n",
    "# Evaluate models\n",
    "for task_name, model, tokenizer in [(\"bias\", bias_model, bias_tokenizer), (\"stereotype\", stereotype_model, stereotype_tokenizer)]:\n",
    "    # Load test data\n",
    "    #Give path to test data\n",
    "    test_csv_path = \"Dataset/StereoSet/test.csv\" if task_name=='stereotype' else \"Dataset/ToxicBias/test.csv\"\n",
    "    test_data = load_test_data(test_csv_path)\n",
    "    print(f\"Evaluating {task_name} model...\")\n",
    "    conf_matrix, class_report = evaluate_model(model, tokenizer, test_data, task_name)\n",
    "\n",
    "    print(\"---------------------------------Confusion Matrix------------------------------------\")\n",
    "    print(pd.DataFrame(conf_matrix))\n",
    "\n",
    "    print(\"---------------------------------Evaluation Metrics------------------------------------\")\n",
    "    print(pd.DataFrame(class_report).transpose())\n",
    "        \n",
    "    # Save results to CSV\n",
    "    result_csv_path = f\"./results/{task_name}_{model_name}_results.csv\"\n",
    "    pd.DataFrame(class_report).transpose().to_csv(result_csv_path, index=True)\n",
    "    print(f\"Results saved to {result_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pushpak/aditya/Bias-Stereotype-MTL/STL-MTL/MTL-E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmharness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
