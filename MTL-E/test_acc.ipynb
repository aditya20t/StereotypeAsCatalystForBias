{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pushpak/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence = [\n",
    "    \"I hate Muslim terrorists and the psychotic Muslims in ISIS. Is that allowed in your politically correct version of reality?\",\n",
    "    \"Apparently the emails state he buys meth from gay Islamic party boys who are transphobic hate blacks puppies and illegally voted for Hillary\",\n",
    "    \"None of that would ever have happened if he werent black. What do you mean?\",\n",
    "    \"1000000 women are just idiots? Your simpleminded generalization paints you as seeming to be one too\"\n",
    "]\n",
    "\n",
    "label = [1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which model are you testing\n",
    "model_name = \"albert-xxlarge-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, task_name):\n",
    "    # Load the configuration\n",
    "    config_path = f\"{task_name}_model/{model_name}/config.json\"\n",
    "    config = transformers.AutoConfig.from_pretrained(config_path)\n",
    "\n",
    "    # Load the model state dict\n",
    "    model_path = f\"{task_name}_model/{model_name}/pytorch_model.bin\"\n",
    "    model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "        pretrained_model_name_or_path=None,\n",
    "        config=config,\n",
    "        state_dict=torch.load(model_path)\n",
    "    )\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(f\"{task_name}_model/{model_name}\")\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load test data from CSV\n",
    "def load_test_data(csv_path):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, test_data, task_name, batch_size=8):\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    sentences = []\n",
    "    \n",
    "    for i in range(0, len(test_data), batch_size):\n",
    "        batch_data = test_data.iloc[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_data['Sentence'].tolist(), max_length=128, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        labels = torch.tensor(batch_data['labels'].tolist())\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        true_list.extend(labels.cpu().numpy())\n",
    "        pred_list.extend(predictions)\n",
    "        sentences.extend(batch_data['Sentence'].tolist())\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    conf_matrix = confusion_matrix(true_list, pred_list)\n",
    "    class_report = classification_report(true_list, pred_list, output_dict=True)\n",
    "    df_data = {\n",
    "        \"Sentence\": sentences,\n",
    "        \"True\": true_list,\n",
    "        \"Predicted\": pred_list\n",
    "    }\n",
    "    df = pd.DataFrame(df_data)\n",
    "    df.to_csv(f\"{task_name}_results.csv\", index=False)\n",
    "    return conf_matrix, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3466313/1288519749.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict=torch.load(model_path)\n",
      "/tmp/ipykernel_3466313/1288519749.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict=torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Sentence  labels  \\\n",
      "0    As the Black Lives Matter movement grows, comp...       0   \n",
      "1    The case of Rahaf Mohammed al-Qunun drawn new ...       0   \n",
      "2    The Post said the talks on payroll taxes were ...       0   \n",
      "3    Nearly 78 percent of Americans report experien...       0   \n",
      "4    Colin P. Clarke has been teaching a course on ...       0   \n",
      "..                                                 ...     ...   \n",
      "995  Monday for his show’s opening monologue, Fox N...       1   \n",
      "996  Under the changes, all military style semi-aut...       0   \n",
      "997  The idea of imposing a wealth tax on the riche...       0   \n",
      "998  The poisonings come more than five months into...       0   \n",
      "999  So you have the New York Times, the Tax Policy...       1   \n",
      "\n",
      "                 topic    id  \n",
      "0    marriage-equality     1  \n",
      "1               gender     2  \n",
      "2                taxes     3  \n",
      "3          environment     4  \n",
      "4    white-nationalism     5  \n",
      "..                 ...   ...  \n",
      "995  marriage-equality   996  \n",
      "996        gun-control   997  \n",
      "997       middle-class   998  \n",
      "998              islam   999  \n",
      "999              taxes  1000  \n",
      "\n",
      "[1000 rows x 4 columns]\n",
      "Evaluating bias_2 model...\n",
      "---------------------------------Confusion Matrix------------------------------------\n",
      "     0    1\n",
      "0  394   47\n",
      "1  102  457\n",
      "---------------------------------Evaluation Metrics------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "0              0.794355  0.893424  0.840982   441.000\n",
      "1              0.906746  0.817531  0.859831   559.000\n",
      "accuracy       0.851000  0.851000  0.851000     0.851\n",
      "macro avg      0.850550  0.855478  0.850406  1000.000\n",
      "weighted avg   0.857182  0.851000  0.851518  1000.000\n",
      "Results saved to ./results/bias_2_roberta-large_results.csv\n",
      "                                               Sentence  labels    id\n",
      "0                             She hailed Mother Russia.       1     1\n",
      "1     The mover will be here soon. They don't really...       1     2\n",
      "2     He was being hateful to the server and demandi...       1     3\n",
      "3     In TLC's 90 DAY FIANCE one of the couples was ...       1     4\n",
      "4                   He wore pants that showed his crack       1     5\n",
      "...                                                 ...     ...   ...\n",
      "1694            She was very understanding and flexible       0  1695\n",
      "1695  Sometimes the girls bickered and sniped at eac...       1  1696\n",
      "1696  I'm thinking of going to Somalia. Everyone the...       1  1697\n",
      "1697  The Ukrainian professor taught philosophy at t...       1  1698\n",
      "1698  He cooks dinner for his grandchildren once a w...       0  1699\n",
      "\n",
      "[1699 rows x 3 columns]\n",
      "Evaluating stereotype model...\n",
      "---------------------------------Confusion Matrix------------------------------------\n",
      "     0    1\n",
      "0  745   63\n",
      "1   61  830\n",
      "---------------------------------Evaluation Metrics------------------------------------\n",
      "              precision    recall  f1-score      support\n",
      "0              0.924318  0.922030  0.923172   808.000000\n",
      "1              0.929451  0.931538  0.930493   891.000000\n",
      "accuracy       0.927016  0.927016  0.927016     0.927016\n",
      "macro avg      0.926884  0.926784  0.926833  1699.000000\n",
      "weighted avg   0.927010  0.927016  0.927012  1699.000000\n",
      "Results saved to ./results/stereotype_roberta-large_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "bias_model, bias_tokenizer = load_model(model_name, \"bias_2\")\n",
    "stereotype_model, stereotype_tokenizer = load_model(model_name, \"stereotype\")\n",
    "\n",
    "# Evaluate models\n",
    "for task_name, model, tokenizer in [(\"bias_2\", bias_model, bias_tokenizer), (\"stereotype\", stereotype_model, stereotype_tokenizer)]:\n",
    "    # Load test data\n",
    "    #Give path to test data\n",
    "    test_csv_path = \"Dataset/StereoSet/test.csv\" if task_name=='stereotype' else \"Dataset/BABE/test.csv\"\n",
    "    test_data = load_test_data(test_csv_path)\n",
    "    print(f\"Evaluating {task_name} model...\")\n",
    "    conf_matrix, class_report = evaluate_model(model, tokenizer, test_data, task_name)\n",
    "\n",
    "    print(\"---------------------------------Confusion Matrix------------------------------------\")\n",
    "    print(pd.DataFrame(conf_matrix))\n",
    "\n",
    "    print(\"---------------------------------Evaluation Metrics------------------------------------\")\n",
    "    print(pd.DataFrame(class_report).transpose())\n",
    "        \n",
    "    # Save results to CSV\n",
    "    result_csv_path = f\"./results/{task_name}_{model_name}_results.csv\"\n",
    "    pd.DataFrame(class_report).transpose().to_csv(result_csv_path, index=True)\n",
    "    print(f\"Results saved to {result_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pushpak/aditya/New/MTL-E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmharness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
