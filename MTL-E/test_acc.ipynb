{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence = [\n",
    "    \"I hate Muslim terrorists and the psychotic Muslims in ISIS. Is that allowed in your politically correct version of reality?\",\n",
    "    \"Apparently the emails state he buys meth from gay Islamic party boys who are transphobic hate blacks puppies and illegally voted for Hillary\",\n",
    "    \"None of that would ever have happened if he werent black. What do you mean?\",\n",
    "    \"1000000 women are just idiots? Your simpleminded generalization paints you as seeming to be one too\"\n",
    "]\n",
    "\n",
    "label = [1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which model are you testing\n",
    "model_name = \"bert-large-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, task_name):\n",
    "    # Load the configuration\n",
    "    config_path = f\"MTL-E/{task_name}_model/{model_name}/config.json\"\n",
    "    config = transformers.AutoConfig.from_pretrained(config_path)\n",
    "\n",
    "    # Load the model state dict\n",
    "    model_path = f\"MTL-E/{task_name}_model/{model_name}/pytorch_model.bin\"\n",
    "    model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "        pretrained_model_name_or_path=None,\n",
    "        config=config,\n",
    "        state_dict=torch.load(model_path)\n",
    "    )\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(f\"MTL-E/{task_name}_model/{model_name}\")\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load test data from CSV\n",
    "def load_test_data(csv_path):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, test_data, task_name, batch_size=8):\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    sentences = []\n",
    "    \n",
    "    for i in range(0, len(test_data), batch_size):\n",
    "        batch_data = test_data.iloc[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_data['Sentence'].tolist(), max_length=128, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        labels = torch.tensor(batch_data['labels'].tolist())\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        true_list.extend(labels.cpu().numpy())\n",
    "        pred_list.extend(predictions)\n",
    "        sentences.extend(batch_data['Sentence'].tolist())\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    conf_matrix = confusion_matrix(true_list, pred_list)\n",
    "    class_report = classification_report(true_list, pred_list, output_dict=True)\n",
    "    df_data = {\n",
    "        \"Sentence\": sentences,\n",
    "        \"True\": true_list,\n",
    "        \"Predicted\": pred_list\n",
    "    }\n",
    "    df = pd.DataFrame(df_data)\n",
    "    df.to_csv(f\"{task_name}_results.csv\", index=False)\n",
    "    return conf_matrix, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87208/3601068973.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict=torch.load(model_path)\n",
      "/tmp/ipykernel_87208/3601068973.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict=torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Sentence  identity_attack_x  \\\n",
      "0     As someone pointed out earlier ISIS and radic...           0.800000   \n",
      "1     URL bellamycharlottesvilletwitter  Read up on...           0.506024   \n",
      "2    . . .  she wants to give other women of color ...           0.500000   \n",
      "3    . The whole world hates the white world yet th...           0.500000   \n",
      "4    ... what horrible human beings .... pathetic. ...           0.653333   \n",
      "..                                                 ...                ...   \n",
      "645  Youre right he should pick something else to b...           0.500000   \n",
      "646  Youre right the international condemnation of ...           0.700000   \n",
      "647  Youre the one making claims.  I called you on ...           0.600000   \n",
      "648  Youre white so clearly you dont understand or ...           0.800000   \n",
      "649  Yup I keep telling people people like you are ...           0.636364   \n",
      "\n",
      "     labels          target       category  \\\n",
      "0         1  muslims,whites  religion,race   \n",
      "1         0             NaN           none   \n",
      "2         1          whites    race,gender   \n",
      "3         1          whites           race   \n",
      "4         1      christians       religion   \n",
      "..      ...             ...            ...   \n",
      "645       1          whites           race   \n",
      "646       1            jews       religion   \n",
      "647       1            gays          lgbtq   \n",
      "648       1          whites           race   \n",
      "649       1          blacks           race   \n",
      "\n",
      "                                rationale   id  \n",
      "0    prejudice against whites and muslims    1  \n",
      "1                                     NaN    2  \n",
      "2             prejudice against white men    3  \n",
      "3                prejudice against whites    4  \n",
      "4            prejudice against christians    5  \n",
      "..                                    ...  ...  \n",
      "645              prejudice against whites  646  \n",
      "646                prejudice against jews  647  \n",
      "647                prejudice towards gays  648  \n",
      "648              prejudice against whites  649  \n",
      "649              prejudice against blacks  650  \n",
      "\n",
      "[650 rows x 7 columns]\n",
      "Evaluating bias model...\n",
      "---------------------------------Confusion Matrix------------------------------------\n",
      "    0    1\n",
      "0  46   85\n",
      "1  45  474\n",
      "---------------------------------Evaluation Metrics------------------------------------\n",
      "              precision    recall  f1-score  support\n",
      "0              0.505495  0.351145  0.414414    131.0\n",
      "1              0.847943  0.913295  0.879406    519.0\n",
      "accuracy       0.800000  0.800000  0.800000      0.8\n",
      "macro avg      0.676719  0.632220  0.646910    650.0\n",
      "weighted avg   0.778926  0.800000  0.785693    650.0\n",
      "Results saved to MTL-E/results/bias_roberta-large_results.csv\n",
      "                                               Sentence  labels    id  \\\n",
      "0     The neighborhood's view of the new eritrean fa...       0     1   \n",
      "1     Kristy was prone to hysterics and fainted easily.       0     2   \n",
      "2     An engineer talked to our class today. He was ...       0     3   \n",
      "3      The nurse came in earlier. They all wear scrubs.       0     4   \n",
      "4       If you are a football player, you must be dumb.       1     5   \n",
      "...                                                 ...     ...   ...   \n",
      "998   The man explained that he was getting gender t...       0   999   \n",
      "999   I thought it was weird that he had never picke...       1  1000   \n",
      "1000  The football player is a strong man. He is ver...       0  1001   \n",
      "1001  I knew these gentlemen before I graduated medi...       1  1002   \n",
      "1002  the butcher takes the meat from the cow and pu...       0  1003   \n",
      "\n",
      "        Category  \n",
      "0           Race  \n",
      "1            NaN  \n",
      "2     Profession  \n",
      "3     Profession  \n",
      "4     Profession  \n",
      "...          ...  \n",
      "998          NaN  \n",
      "999       Others  \n",
      "1000  Profession  \n",
      "1001      Gender  \n",
      "1002  Profession  \n",
      "\n",
      "[1003 rows x 4 columns]\n",
      "Evaluating stereotype model...\n",
      "---------------------------------Confusion Matrix------------------------------------\n",
      "     0    1\n",
      "0  496   67\n",
      "1   38  402\n",
      "---------------------------------Evaluation Metrics------------------------------------\n",
      "              precision    recall  f1-score      support\n",
      "0              0.928839  0.880995  0.904284   563.000000\n",
      "1              0.857143  0.913636  0.884488   440.000000\n",
      "accuracy       0.895314  0.895314  0.895314     0.895314\n",
      "macro avg      0.892991  0.897316  0.894386  1003.000000\n",
      "weighted avg   0.897387  0.895314  0.895600  1003.000000\n",
      "Results saved to MTL-E/results/stereotype_roberta-large_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "bias_model, bias_tokenizer = load_model(model_name, \"bias\")\n",
    "stereotype_model, stereotype_tokenizer = load_model(model_name, \"stereotype\")\n",
    "\n",
    "# Evaluate models\n",
    "for task_name, model, tokenizer in [(\"bias\", bias_model, bias_tokenizer), (\"stereotype\", stereotype_model, stereotype_tokenizer)]:\n",
    "    # Load test data\n",
    "    #Give path to test data\n",
    "    test_csv_path = \"MTL-E/Dataset/StereoBias/stereotype/test.csv\" if task_name=='stereotype' else \"MTL-E/Dataset/ToxicBias/test.csv\"\n",
    "    test_data = load_test_data(test_csv_path)\n",
    "    print(f\"Evaluating {task_name} model...\")\n",
    "    conf_matrix, class_report = evaluate_model(model, tokenizer, test_data, task_name)\n",
    "\n",
    "    print(\"---------------------------------Confusion Matrix------------------------------------\")\n",
    "    print(pd.DataFrame(conf_matrix))\n",
    "\n",
    "    print(\"---------------------------------Evaluation Metrics------------------------------------\")\n",
    "    print(pd.DataFrame(class_report).transpose())\n",
    "        \n",
    "    # Save results to CSV\n",
    "    result_csv_path = f\"MTL-E/results/{task_name}_{model_name}_results.csv\"\n",
    "    pd.DataFrame(class_report).transpose().to_csv(result_csv_path, index=True)\n",
    "    print(f\"Results saved to {result_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/nlp/aditya/StereotypeAsCatalystForBias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmharness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
