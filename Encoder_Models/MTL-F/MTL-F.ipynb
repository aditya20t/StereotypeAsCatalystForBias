{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LPQDNZivFSC4"
      },
      "outputs": [],
      "source": [
        "# Change the dataset name to to the csv file name in use\n",
        "dataset_name = \"StereoBias\"\n",
        "\n",
        "# Change the model_name to one of the following names\n",
        "# BERT large    ----> bert-large-uncased\n",
        "# ALBERT large  ----> albert-xxlarge-v2\n",
        "# RoBERTa large ----> roberta-large\n",
        "model_name = \"bert-large-uncased\"\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "# Change the numbers in random_list for 3 runs of 10-fold cross-validation run\n",
        "random_list = [42,101,2020]\n",
        "\n",
        "# Change random_st variable for the 10-fold cross-validation run\n",
        "random_st = 42\n",
        "\n",
        "# Hyperparameters\n",
        "MAX_LEN=64\n",
        "batch_size = 16\n",
        "epochs = 10\n",
        "learning_rate = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p0IF3Y-8L3N2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2025-02-06 10:55:17.987866: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-02-06 10:55:18.007867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1738819518.031573   18544 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1738819518.038735   18544 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-06 10:55:18.064752: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
            "  warnings.warn(\n",
            "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
            "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
            "/data/nlp/aditya/miniforge3/envs/lmharness/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
            "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "!pip install transformers --quiet\n",
        "from transformers import *\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
        "\n",
        "import pickle\n",
        "from tqdm import tqdm, trange\n",
        "import tensorflow as tf\n",
        "\n",
        "from operator import itemgetter\n",
        "from statistics import mean, stdev\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ltYi2ml7Ih5f"
      },
      "outputs": [],
      "source": [
        "# Set the seed value\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ96w8HnMBaj",
        "outputId": "06a487dc-5fb2-45cb-dfdb-ee69dba7544c"
      },
      "outputs": [],
      "source": [
        "# Check for GPU device\n",
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:2':\n",
        "#   raise SystemError('GPU device not found!')\n",
        "# print('GPU found at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODeQlNjCVnUN",
        "outputId": "b6c4d46f-3a6b-4593-ef23-807af7225d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA A100 80GB PCIe\n"
          ]
        }
      ],
      "source": [
        "# Set the GPU device\n",
        "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperbole -> bias\n",
        "## Metaphor -> Stereotype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "o9qwqdRGMDEA",
        "outputId": "462a53a7-542b-4b72-f00f-08d4138e917d"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'StereoBias.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the csv data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/miniforge3/envs/lmharness/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniforge3/envs/lmharness/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/miniforge3/envs/lmharness/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniforge3/envs/lmharness/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/miniforge3/envs/lmharness/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'StereoBias.csv'"
          ]
        }
      ],
      "source": [
        "# Read the csv data\n",
        "df = pd.read_csv(dataset_name+'.csv')\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df = df.dropna(axis=0).reset_index(drop=True)\n",
        "\n",
        "df[\"bias\"] = df[\"bias\"].astype(\"int\")\n",
        "df[\"stereotype\"] = df[\"stereotype\"].astype(\"int\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqIYfiutMcXL",
        "outputId": "d5b6403c-e002-4e1a-a2cf-5c72a03d10a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label columns:  ['Hyperbole', 'Metaphor']\n"
          ]
        }
      ],
      "source": [
        "cols = df.columns\n",
        "label_cols = list(cols[1:])\n",
        "num_labels = len(label_cols)\n",
        "print('Label columns: ', label_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n7icAoehMoH3",
        "outputId": "05389799-3bad-477e-c8ad-09b01c6ff60b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9d86d2dc-b4a8-4923-827d-3b65375f1685\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Hyperbole</th>\n",
              "      <th>Metaphor</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Insolent boy, I'll slash you to ribbons!</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The level of discombobulation in the realm of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>His eyes were very dark.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's been a long time since I found someone ni...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, you are soaked to the bone, monsieur.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d86d2dc-b4a8-4923-827d-3b65375f1685')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d86d2dc-b4a8-4923-827d-3b65375f1685 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d86d2dc-b4a8-4923-827d-3b65375f1685');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Sentence  Hyperbole  Metaphor  \\\n",
              "0           Insolent boy, I'll slash you to ribbons!          1         1   \n",
              "1  The level of discombobulation in the realm of ...          1         1   \n",
              "2                           His eyes were very dark.          0         0   \n",
              "3  It's been a long time since I found someone ni...          0         0   \n",
              "4          Oh, you are soaked to the bone, monsieur.          1         1   \n",
              "\n",
              "  one_hot_labels  \n",
              "0         [1, 1]  \n",
              "1         [1, 1]  \n",
              "2         [0, 0]  \n",
              "3         [0, 0]  \n",
              "4         [1, 1]  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['one_hot_labels'] = list(df[label_cols].values)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CdwHQWt6DYpS",
        "outputId": "2d9275be-bfd8-4c50-c657-52132dc92fb1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-44c36e13-386e-42b7-bb3b-a04f7629956b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Hyperbole</th>\n",
              "      <th>Metaphor</th>\n",
              "      <th>one_hot_labels</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Insolent boy, I'll slash you to ribbons!</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The level of discombobulation in the realm of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>His eyes were very dark.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's been a long time since I found someone ni...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, you are soaked to the bone, monsieur.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44c36e13-386e-42b7-bb3b-a04f7629956b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44c36e13-386e-42b7-bb3b-a04f7629956b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44c36e13-386e-42b7-bb3b-a04f7629956b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Sentence  Hyperbole  Metaphor  \\\n",
              "0           Insolent boy, I'll slash you to ribbons!          1         1   \n",
              "1  The level of discombobulation in the realm of ...          1         1   \n",
              "2                           His eyes were very dark.          0         0   \n",
              "3  It's been a long time since I found someone ni...          0         0   \n",
              "4          Oh, you are soaked to the bone, monsieur.          1         1   \n",
              "\n",
              "  one_hot_labels  new  \n",
              "0         [1, 1]    3  \n",
              "1         [1, 1]    3  \n",
              "2         [0, 0]    0  \n",
              "3         [0, 0]    0  \n",
              "4         [1, 1]    3  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conditions = [\n",
        "    (df[\"Hyperbole\"]==0) & (df[\"Metaphor\"]==0),\n",
        "    (df[\"Hyperbole\"]==0) & (df[\"Metaphor\"]==1),\n",
        "    (df[\"Hyperbole\"]==1) & (df[\"Metaphor\"]==0),\n",
        "    (df[\"Hyperbole\"]==1) & (df[\"Metaphor\"]==1)\n",
        "]\n",
        "choices = [0,1,2,3]\n",
        "\n",
        "df[\"new\"] = np.select(conditions, choices)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzmtxtiEDYpT",
        "outputId": "1fbdbbe3-fcce-4790-c099-e411f1bf5e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    796\n",
            "1    622\n",
            "Name: Metaphor, dtype: int64\n",
            "1    709\n",
            "0    709\n",
            "Name: Hyperbole, dtype: int64\n",
            "0    602\n",
            "3    515\n",
            "2    194\n",
            "1    107\n",
            "Name: new, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"Metaphor\"].value_counts())\n",
        "print(df[\"Hyperbole\"].value_counts())\n",
        "print(df.new.value_counts())\n",
        "\n",
        "y= df[\"new\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UwTrTHdgMtFt"
      },
      "outputs": [],
      "source": [
        "labels = list(df.one_hot_labels.values)\n",
        "comments = list(df.Sentence.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "de54939599c247b18b9f64f798ecb92d",
            "35f607b3410b4f2685b9dd32199186fe",
            "dfde771e9ea54b118c466848410ee0dd",
            "079b0dd8be4848d78f8afb1308d43b40",
            "053fe08a58a1429cb10ab97c4b2492de",
            "fce6f4faae3a44d882f3a29a021f72e2",
            "fc7371717a0641ce9454903980b15fc0",
            "62855445029c4291b1ae47fba4b658d9",
            "28c0c7a694894cc8abd55ad8b1644b27",
            "8edb39e2fce84d6ba6310db67996835a",
            "979c7eae0b78482ba1ca5cc94fb0c4a9",
            "c09c0a7e8aab422e9736c5dd35f7b19d",
            "fe9db4c1f3d0455781cbad971fd05294",
            "618e0e1d878c4872888777280b3d7a79",
            "035c7745ba774040834144e2b1cbaefc",
            "b6c35c937f0d44ed86735b3e1fd47a24",
            "710963428e544ce898264e8422434852",
            "e0f5d2114b38472f8972e991b27a51f1",
            "f50f07c7efd44282ae5e963725684dd2",
            "2541d1bff8b94acc80c1b93a463588da",
            "f21f279d04a24f30a9cdbb04567a1129",
            "0d013aaf5cab48579ba671a633f2b723",
            "af30ba2e6822481b938ee5e8a95abfe7",
            "fcf2e0c8af444cac8f2da731c97c14d4",
            "c8c187b8474144edb6d890292bd5df62",
            "ed80d9d6b3604fbf985da258810e1283",
            "cd99997b376243419de6640f43a8eadc",
            "ace2e5b5e08e4051bf30acdb6d4e21c9",
            "b2e9706c53c343dea13953287f7f50b7",
            "f67adb00c2024e63b764263909fb3a06",
            "cd40a6b8a20c4638a65c8efd6139a5b9",
            "42cf76738723468c89bb91da3a286474",
            "43e03a0f43ba4b4b997c09d4a295ab82",
            "e5b06189106b44f083b6553d728e3d7f",
            "794024b537534aa6a83355bb14e69ac0",
            "ec1d3996802247ab9a404a4a3afe88b3",
            "dc7fd42fd3ff44cc9baaf591664ae4e5",
            "d624bbe8b12f4dc3b98321cf292b43f3",
            "4b9c9d490dce43429307804fc91b3d4c",
            "b5065294ebbf47bfa22566be004a1118",
            "77497eb681d24d579479125788ee99c6",
            "318abcab4e1c4c90986b2c44ed7fafca",
            "bb728348a7a747fca6a449354ea43a1c",
            "89f7e455c5e241f4bd3be6191c1cf79e",
            "5596ef02038847429eeae270b0abd9a9",
            "fb811041a4b046429998521520cee351",
            "edbd30c11faa4cf6b0d1782d732a0a48",
            "a7a33d4939d245f28ede93b3057eac62",
            "e14e2a2b0f99428091deff9b0a33025c",
            "aaa05385a09542a7ad5929fe040b55e0",
            "e000a0eb8b554a2c96c171a175935d98",
            "8e8f29311c444630944fee8548d27442",
            "352f7b0297e54ffb98d55402103c803c",
            "0fd0d958493e4bdcbab4f3d4a876c0c8",
            "9b396d871c9b4553a4cb0679641b4d7d"
          ]
        },
        "id": "tIPLo7S0eoeU",
        "outputId": "d19356bf-e161-43d4-ac36-e201d0149a14"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de54939599c247b18b9f64f798ecb92d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_attentions\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c09c0a7e8aab422e9736c5dd35f7b19d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af30ba2e6822481b938ee5e8a95abfe7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5b06189106b44f083b6553d728e3d7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5596ef02038847429eeae270b0abd9a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, output_attentions=True) \n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E5k2SJFewiz",
        "outputId": "ec7e2d1a-8f7b-436e-a04a-74edd4bcda32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original:  A day was twenty-four hours long but seemed longer.\n",
            "Token IDs: [101, 100, 2038, 1037, 2200, 8052, 3716, 2055, 1996, 8605, 5130, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "MASK IDs: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "101 102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    tokenizer.padding_side = 'right'\n",
        "    try:\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "                            df['Sentence'][i],            # Sentence to encode.\n",
        "                            add_special_tokens = True, \n",
        "                            max_length = MAX_LEN,\n",
        "                            pad_to_max_length = True\n",
        "                            )\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    input_ids.append(encoded_sent['input_ids'])\n",
        "    attention_masks.append(encoded_sent['attention_mask'])\n",
        "\n",
        "\n",
        "print('original: ' , df['Sentence'][100])\n",
        "print('Token IDs:', input_ids[-1])\n",
        "print('MASK IDs:', attention_masks[-1])\n",
        "print(tokenizer.cls_token_id, tokenizer.sep_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaHUmmotDYpd",
        "outputId": "f2362d73-f5fe-4036-9dbb-2e41d0a51610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of samples:  1418\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of samples: \", len(input_ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjWstjW4Wq4E"
      },
      "source": [
        "Run the following cell for 3 runs of 10-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_75LQh83DYpk",
        "outputId": "5ca9b5ce-8676-4457-9b59-014f03681d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------FOLD NO:  0\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_attentions\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(train_dataloader) 80\n",
            "total_steps 800\n",
            "warmup_steps 48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.6757181629538536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 1/10 [00:57<08:39, 57.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  56.65236051502145\n",
            "Flat Validation Accuracy:  50.70422535211267\n",
            "Train loss: 0.5403035182505846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [01:54<07:38, 57.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  75.4325259515571\n",
            "Flat Validation Accuracy:  64.08450704225352\n",
            "Train loss: 0.4188168980181217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [02:51<06:40, 57.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  78.6206896551724\n",
            "Flat Validation Accuracy:  67.6056338028169\n",
            "Train loss: 0.3439780404791236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [03:48<05:42, 57.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  79.3103448275862\n",
            "Flat Validation Accuracy:  67.6056338028169\n",
            "Train loss: 0.28911166498437524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [04:45<04:45, 57.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  79.71014492753623\n",
            "Flat Validation Accuracy:  69.01408450704226\n",
            "Train loss: 0.254831931181252\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [05:42<03:48, 57.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  78.65168539325845\n",
            "Flat Validation Accuracy:  69.71830985915493\n",
            "Train loss: 0.2174176118336618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 7/10 [06:39<02:50, 56.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  78.81040892193309\n",
            "Flat Validation Accuracy:  69.01408450704226\n",
            "Train loss: 0.19466794058680534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 8/10 [07:36<01:53, 56.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  78.94736842105262\n",
            "Flat Validation Accuracy:  69.71830985915493\n",
            "Train loss: 0.17672800784930587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 9/10 [08:33<00:56, 56.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  78.96678966789669\n",
            "Flat Validation Accuracy:  68.30985915492957\n",
            "Train loss: 0.1664030622225255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 10/10 [09:30<00:00, 57.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  78.7878787878788\n",
            "Flat Validation Accuracy:  70.4225352112676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test F1 Accuracy:  0.787878787878788\n",
            "Test Flat Accuracy:  0.704225352112676 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Hyperbole       0.83      0.86      0.84        72\n",
            "    Metaphor       0.76      0.68      0.72        62\n",
            "\n",
            "   micro avg       0.80      0.78      0.79       134\n",
            "   macro avg       0.80      0.77      0.78       134\n",
            "weighted avg       0.80      0.78      0.79       134\n",
            " samples avg       0.42      0.43      0.42       134\n",
            "\n",
            "\n",
            "---------------------------------FOLD NO:  1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_attentions\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(train_dataloader) 80\n",
            "total_steps 800\n",
            "warmup_steps 48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.688147522509098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 1/10 [00:57<08:37, 57.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  75.7396449704142\n",
            "Flat Validation Accuracy:  54.22535211267606\n",
            "Train loss: 0.5321263313293457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [01:54<07:36, 57.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  81.4814814814815\n",
            "Flat Validation Accuracy:  70.4225352112676\n",
            "Train loss: 0.3950997106730938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [02:51<06:38, 56.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  81.29496402877699\n",
            "Flat Validation Accuracy:  69.71830985915493\n",
            "Train loss: 0.3396463718265295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [03:48<05:41, 56.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  81.8840579710145\n",
            "Flat Validation Accuracy:  71.12676056338029\n",
            "Train loss: 0.29527360536158087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [04:44<04:44, 56.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  77.91164658634538\n",
            "Flat Validation Accuracy:  69.71830985915493\n",
            "Train loss: 0.270494319871068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [05:41<03:47, 56.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  76.11336032388664\n",
            "Flat Validation Accuracy:  68.30985915492957\n",
            "Train loss: 0.24305321834981441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 7/10 [06:38<02:50, 56.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  77.16535433070867\n",
            "Flat Validation Accuracy:  69.71830985915493\n",
            "Train loss: 0.22248841347172857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 8/10 [07:35<01:53, 56.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  75.60975609756098\n",
            "Flat Validation Accuracy:  68.30985915492957\n",
            "Train loss: 0.2108799707144499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 9/10 [08:32<00:56, 56.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  76.8\n",
            "Flat Validation Accuracy:  68.30985915492957\n",
            "Train loss: 0.19848606670275332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 10/10 [09:29<00:00, 56.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  77.10843373493977\n",
            "Flat Validation Accuracy:  69.01408450704226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test F1 Accuracy:  0.7710843373493976\n",
            "Test Flat Accuracy:  0.6901408450704225 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Hyperbole       0.87      0.77      0.82        71\n",
            "    Metaphor       0.79      0.65      0.71        63\n",
            "\n",
            "   micro avg       0.83      0.72      0.77       134\n",
            "   macro avg       0.83      0.71      0.77       134\n",
            "weighted avg       0.83      0.72      0.77       134\n",
            " samples avg       0.38      0.38      0.37       134\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "final_list = []\n",
        "for ran in random_list:\n",
        "    random_state = ran\n",
        "    kf = StratifiedKFold(n_splits=10, random_state=random_state, shuffle=True)\n",
        "\n",
        "    f1_list = []\n",
        "    for i,(train_index, validation_index) in enumerate(kf.split(input_ids,y)):\n",
        "      # if i==2:  \n",
        "      #   break\n",
        "      z=i\n",
        "      print()\n",
        "      print(\"---------------------------------FOLD NO: \", i)\n",
        "      print()\n",
        "      train_inputs = list(itemgetter(*train_index)(input_ids))\n",
        "      train_labels = list(itemgetter(*train_index)(labels))\n",
        "      train_masks = list(itemgetter(*train_index)(attention_masks))\n",
        "\n",
        "      validation_inputs = list(itemgetter(*validation_index)(input_ids))\n",
        "      validation_labels = list(itemgetter(*validation_index)(labels))\n",
        "      validation_masks = list(itemgetter(*validation_index)(attention_masks))\n",
        "\n",
        "      train_inputs = torch.tensor(train_inputs)\n",
        "      validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "      train_labels = torch.tensor(train_labels)\n",
        "      validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "      train_masks = torch.tensor(train_masks)\n",
        "      validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "      train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "      train_sampler = RandomSampler(train_data)\n",
        "      train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "      validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "      validation_sampler = SequentialSampler(validation_data)\n",
        "      validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "      model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, output_attentions=True)\n",
        "      tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
        "      model.cuda()\n",
        "\n",
        "      optimizer = AdamW(model.parameters(),\n",
        "                        lr = learning_rate,\n",
        "                        eps = 1e-8\n",
        "                      )\n",
        "\n",
        "      train_loss_set = []\n",
        "\n",
        "      print('len(train_dataloader)', len(train_dataloader))\n",
        "      total_steps = len(train_dataloader) * epochs\n",
        "      print('total_steps', total_steps)\n",
        "      warmup_steps = int(0.06 * total_steps)\n",
        "      print('warmup_steps', warmup_steps)\n",
        "     \n",
        "      scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                                  num_warmup_steps = warmup_steps, \n",
        "                                                  num_training_steps = total_steps)\n",
        "\n",
        "      \n",
        "      for _ in trange(epochs, desc=\"Epoch\"):\n",
        "        model.train()\n",
        "\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "        # Train the data for one epoch\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "          \n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "         \n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "          logits = outputs[0]\n",
        "          loss_func = BCEWithLogitsLoss() \n",
        "          loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "          train_loss_set.append(loss.item())    \n",
        "\n",
        "         \n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "          \n",
        "          tr_loss += loss.item()\n",
        "          nb_tr_examples += b_input_ids.size(0)\n",
        "          nb_tr_steps += 1\n",
        "\n",
        "        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "      ###############################################################################\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "\n",
        "        logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "        for i, batch in enumerate(validation_dataloader):\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          with torch.no_grad():\n",
        "            \n",
        "            outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            b_logit_pred = outs[0]\n",
        "            pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "            b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "            pred_label = pred_label.to('cpu').numpy()\n",
        "            b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "          tokenized_texts.append(b_input_ids)\n",
        "          logit_preds.append(b_logit_pred)\n",
        "          true_labels.append(b_labels)\n",
        "          pred_labels.append(pred_label)\n",
        "\n",
        "        pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "        true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "        threshold = 0.50\n",
        "        pred_bools = [pl>threshold for pl in pred_labels]\n",
        "        true_bools = [tl==1 for tl in true_labels]\n",
        "        val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
        "        val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
        "\n",
        "        print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
        "        print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
        "\n",
        "       \n",
        "      model.eval()\n",
        "\n",
        "      logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "      for i, batch in enumerate(validation_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "         \n",
        "          outs = model(b_input_ids, attention_mask=b_input_mask)\n",
        "          b_logit_pred = outs[0]\n",
        "          pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "          b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "          pred_label = pred_label.to('cpu').numpy()\n",
        "          b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "        tokenized_texts.append(b_input_ids)\n",
        "        logit_preds.append(b_logit_pred)\n",
        "        true_labels.append(b_labels)\n",
        "        pred_labels.append(pred_label)\n",
        "\n",
        "      \n",
        "      tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
        "      pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "      true_labels = [item for sublist in true_labels for item in sublist]\n",
        "      \n",
        "      true_bools = [tl==1 for tl in true_labels]\n",
        "\n",
        "      pred_bools = [pl>0.50 for pl in pred_labels] \n",
        "\n",
        "      # Print and save classification report\n",
        "      print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
        "      print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
        "      clf_report = classification_report(true_bools,pred_bools,target_names=label_cols)\n",
        "  \n",
        "      print(clf_report)\n",
        "      f1_list.append(clf_report)\n",
        "\n",
        "    final_list.extend(f1_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5pE4EUYuDYpk"
      },
      "outputs": [],
      "source": [
        "# Collect the results\n",
        "hp=[]\n",
        "hr=[]\n",
        "hf1=[]\n",
        "\n",
        "mp=[]\n",
        "mr=[]\n",
        "mf1=[]\n",
        "\n",
        "for i in range(len(final_list)):\n",
        "    temp=final_list[i].split()\n",
        "    hp.append(float(temp[5]))\n",
        "    hr.append(float(temp[6]))\n",
        "    hf1.append(float(temp[7]))\n",
        "    \n",
        "    mp.append(float(temp[10]))\n",
        "    mr.append(float(temp[11]))\n",
        "    mf1.append(float(temp[12]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsXluGxVDYpl",
        "outputId": "ca6dec22-fcc3-4b99-9b49-50683014629a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperbole Results\n",
            "\n",
            "Precision 0.85\n",
            "Recall 0.815\n",
            "F1 score 0.83\n",
            "Std Dev 0.014142135623730963\n"
          ]
        }
      ],
      "source": [
        "print(\"Hyperbole Results\")\n",
        "print()\n",
        "print(\"Precision\",mean(hp))\n",
        "print(\"Recall\",mean(hr))\n",
        "print(\"F1 score\",mean(hf1))\n",
        "print(\"Std Dev\",stdev(hf1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9YubODBDYpm",
        "outputId": "cea5d54e-6fea-4f72-d7c4-4e9d1b9c69ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metaphor Results\n",
            "\n",
            "Precision 0.775\n",
            "Recall 0.665\n",
            "F1 score 0.715\n",
            "Std Dev 0.007071067811865481\n"
          ]
        }
      ],
      "source": [
        "print(\"Metaphor Results\")\n",
        "print()\n",
        "print(\"Precision\",mean(mp))\n",
        "print(\"Recall\",mean(mr))\n",
        "print(\"F1 score\",mean(mf1))\n",
        "print(\"Std Dev\",stdev(mf1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHIASwAtXSeb"
      },
      "source": [
        "Run the following cell to obtain prediction files and models for 10-fold cross validation (single run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhd61b_rDYpt",
        "outputId": "815bba84-2ff2-4859-da73-32827e5f78b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------FOLD NO:  0\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_attentions\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(train_dataloader) 80\n",
            "total_steps 800\n",
            "warmup_steps 48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.6972253732383251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 1/10 [00:50<07:38, 50.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  71.03448275862068\n",
            "Flat Validation Accuracy:  57.04225352112676\n",
            "Train loss: 0.5362343434244394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [01:44<06:57, 52.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  70.28985507246377\n",
            "Flat Validation Accuracy:  59.154929577464785\n",
            "Train loss: 0.4463025700300932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [02:38<06:12, 53.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  76.05633802816901\n",
            "Flat Validation Accuracy:  65.49295774647888\n",
            "Train loss: 0.3744270529597998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [03:34<05:25, 54.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  75.9581881533101\n",
            "Flat Validation Accuracy:  65.49295774647888\n",
            "Train loss: 0.31567469649016855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [04:30<04:34, 54.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  74.45255474452556\n",
            "Flat Validation Accuracy:  63.38028169014085\n",
            "Train loss: 0.28720657592639326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [05:27<03:42, 55.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  73.88059701492537\n",
            "Flat Validation Accuracy:  63.38028169014085\n",
            "Train loss: 0.26255414728075266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 7/10 [06:23<02:47, 55.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  75.45787545787545\n",
            "Flat Validation Accuracy:  65.49295774647888\n",
            "Train loss: 0.24092725086957217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 8/10 [07:20<01:52, 56.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  76.22641509433961\n",
            "Flat Validation Accuracy:  67.6056338028169\n",
            "Train loss: 0.22981519885361196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 9/10 [08:17<00:56, 56.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  76.33587786259542\n",
            "Flat Validation Accuracy:  68.30985915492957\n",
            "Train loss: 0.2146954125724733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 10/10 [09:14<00:00, 55.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  76.8060836501901\n",
            "Flat Validation Accuracy:  68.30985915492957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Configuration saved in new_combined/mtl/42/model0/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test F1 Accuracy:  0.768060836501901\n",
            "Test Flat Accuracy:  0.6830985915492958 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Hyperbole       0.82      0.82      0.82        72\n",
            "    Metaphor       0.74      0.68      0.71        62\n",
            "\n",
            "   micro avg       0.78      0.75      0.77       134\n",
            "   macro avg       0.78      0.75      0.76       134\n",
            "weighted avg       0.78      0.75      0.77       134\n",
            " samples avg       0.39      0.42      0.40       134\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in new_combined/mtl/42/model0/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "kf = StratifiedKFold(n_splits=10, random_state=random_st, shuffle=True)\n",
        "f1_list = []\n",
        "for i,(train_index, validation_index) in enumerate(kf.split(input_ids,y)):\n",
        "  # if i==1:\n",
        "  #   break\n",
        "  z=i\n",
        "  print()\n",
        "  print(\"---------------------------------FOLD NO: \", i)\n",
        "  print()\n",
        "  train_inputs = list(itemgetter(*train_index)(input_ids))\n",
        "  train_labels = list(itemgetter(*train_index)(labels))\n",
        "  train_masks = list(itemgetter(*train_index)(attention_masks))\n",
        "\n",
        "  validation_inputs = list(itemgetter(*validation_index)(input_ids))\n",
        "  validation_labels = list(itemgetter(*validation_index)(labels))\n",
        "  validation_masks = list(itemgetter(*validation_index)(attention_masks))\n",
        "\n",
        "  train_inputs = torch.tensor(train_inputs)\n",
        "  validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "  train_labels = torch.tensor(train_labels)\n",
        "  validation_labels = torch.tensor(validation_labels)\n",
        "  \n",
        "  train_masks = torch.tensor(train_masks)\n",
        "  validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "  validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "  validation_sampler = SequentialSampler(validation_data)\n",
        "  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, output_attentions=True)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
        "  model.cuda()\n",
        "\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                    lr = learning_rate, \n",
        "                    eps = 1e-8 \n",
        "                  )\n",
        "\n",
        "  train_loss_set = []\n",
        "    \n",
        "  print('len(train_dataloader)', len(train_dataloader))\n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "  print('total_steps', total_steps)\n",
        "  warmup_steps = int(0.06 * total_steps)\n",
        "  print('warmup_steps', warmup_steps)\n",
        " \n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = warmup_steps, # Default value in run_glue.py\n",
        "                                              num_training_steps = total_steps)\n",
        "\n",
        "  \n",
        "  for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "    # Training\n",
        "  \n",
        "    model.train()\n",
        "    tr_loss = 0 \n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    \n",
        "    \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      \n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      logits = outputs[0]\n",
        "      loss_func = BCEWithLogitsLoss() \n",
        "      loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "      train_loss_set.append(loss.item())    \n",
        "\n",
        "      \n",
        "      loss.backward()\n",
        "      \n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "    \n",
        "      tr_loss += loss.item()\n",
        "      nb_tr_examples += b_input_ids.size(0)\n",
        "      nb_tr_steps += 1\n",
        "\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "  ###############################################################################\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    model.eval()\n",
        "    logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "    # Predict\n",
        "    for i, batch in enumerate(validation_dataloader):\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "      with torch.no_grad():\n",
        "      \n",
        "        outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        b_logit_pred = outs[0]\n",
        "        pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "        b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "        pred_label = pred_label.to('cpu').numpy()\n",
        "        b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "      tokenized_texts.append(b_input_ids)\n",
        "      logit_preds.append(b_logit_pred)\n",
        "      true_labels.append(b_labels)\n",
        "      pred_labels.append(pred_label)\n",
        "\n",
        "   \n",
        "    pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "    true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  \n",
        "    threshold = 0.50\n",
        "    pred_bools = [pl>threshold for pl in pred_labels]\n",
        "    true_bools = [tl==1 for tl in true_labels]\n",
        "    val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
        "    val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
        "\n",
        "    print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
        "    print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
        "\n",
        "  \n",
        "  model.eval()\n",
        "\n",
        "  \n",
        "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "\n",
        "  for i, batch in enumerate(validation_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      outs = model(b_input_ids, attention_mask=b_input_mask)\n",
        "      b_logit_pred = outs[0]\n",
        "      pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "\n",
        "  tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "  \n",
        "  true_bools = [tl==1 for tl in true_labels]\n",
        "\n",
        "  pred_bools = [pl>0.50 for pl in pred_labels] \n",
        "\n",
        "  print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
        "  print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
        "  clf_report = classification_report(true_bools,pred_bools,target_names=label_cols)\n",
        "  \n",
        "  print(clf_report)\n",
        "  f1_list.append(clf_report)\n",
        "  \n",
        "  path_name = dataset_name + \"/mtl/\" + str(random_st)\n",
        "  file_path = path_name + \"/predictions\"+str(z)+ \".csv\"\n",
        "  model_path = path_name + \"/model\" + str(z)\n",
        "\n",
        "  if not os.path.exists(path_name):\n",
        "    os.makedirs(path_name)\n",
        "  \n",
        "  val_sent = list(itemgetter(*validation_index)(df.Sentence.values))\n",
        "\n",
        "  pred_df = pd.DataFrame(list(zip(val_sent, true_bools, pred_bools)), columns=[\"sentence\",\"true_label\",\"pred_label\"])\n",
        "  pred_df.to_csv(file_path)\n",
        "  model.save_pretrained(model_path)  \n",
        "    \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qRoaP2Xpe5bG"
      },
      "outputs": [],
      "source": [
        "# Collect the results\n",
        "hp=[]\n",
        "hr=[]\n",
        "hf1=[]\n",
        "\n",
        "mp=[]\n",
        "mr=[]\n",
        "mf1=[]\n",
        "\n",
        "for i in range(len(f1_list)):\n",
        "    temp=final_list[i].split()\n",
        "    hp.append(float(temp[5]))\n",
        "    hr.append(float(temp[6]))\n",
        "    hf1.append(float(temp[7]))\n",
        "    \n",
        "    mp.append(float(temp[10]))\n",
        "    mr.append(float(temp[11]))\n",
        "    mf1.append(float(temp[12]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHmJ8nJMe93X"
      },
      "outputs": [],
      "source": [
        "print(\"Hyperbole Results\")\n",
        "print()\n",
        "print(\"Precision\",mean(hp))\n",
        "print(\"Recall\",mean(hr))\n",
        "print(\"F1 score\",mean(hf1))\n",
        "print(\"Std Dev\",stdev(hf1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AzZUtO9fAnx"
      },
      "outputs": [],
      "source": [
        "print(\"Metaphor Results\")\n",
        "print()\n",
        "print(\"Precision\",mean(mp))\n",
        "print(\"Recall\",mean(mr))\n",
        "print(\"F1 score\",mean(mf1))\n",
        "print(\"Std Dev\",stdev(mf1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ufJ9kKVc3XX"
      },
      "source": [
        "Inference on example sentences and attention weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6MUQPLScBTU",
        "outputId": "303d9d4e-cbaa-40c6-8264-e10adfaf1c58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file new_combined/mtl/42/model0/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"new_combined/mtl/42/model0\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_attentions\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file new_combined/mtl/42/model0/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at new_combined/mtl/42/model0.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "input_text = \"He went a thousand miles to be here.\"\n",
        "\n",
        "\n",
        "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
        "model = AutoModelForSequenceClassification.from_pretrained(path_name + \"/model0\", output_attentions=True) \n",
        "model.cuda()\n",
        "outputs = model(inputs.to(device))  # Run model\n",
        "attention = outputs[-1]  # Retrieve attention from model outputs\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFe65fJhfLJ5",
        "outputId": "8250da3a-00a8-42cf-fddd-5d8fdf7f5a49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.1706, 0.0204, 0.0719, 0.2325, 0.0764, 0.0478, 0.0261, 0.0315, 0.0291,\n",
              "        0.2276, 0.0661], device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum = torch.zeros(len(tokens),len(tokens))\n",
        "for i in range(16):\n",
        "    if i==0:\n",
        "        sum=outputs[-1][-1][0][i]\n",
        "    sum = torch.add(sum,outputs[-1][-1][0][i])\n",
        "#     outputs[-1][-1][0][0]\n",
        "sum[0]/torch.sum(sum[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "cXpICBQwfrOg",
        "outputId": "37f74766-a8c1-4f92-cdef-1e383cd88940"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-11974b2b-a1b1-443c-9b7d-84e9bf4396ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>[ U N K ]</th>\n",
              "      <th>w e n t</th>\n",
              "      <th>a</th>\n",
              "      <th>t h o u s a n d</th>\n",
              "      <th>m i l e s</th>\n",
              "      <th>t o</th>\n",
              "      <th>b e</th>\n",
              "      <th>h e r e</th>\n",
              "      <th>.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.028354</td>\n",
              "      <td>0.100813</td>\n",
              "      <td>0.284534</td>\n",
              "      <td>0.107489</td>\n",
              "      <td>0.066532</td>\n",
              "      <td>0.036349</td>\n",
              "      <td>0.044139</td>\n",
              "      <td>0.040933</td>\n",
              "      <td>0.290856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11974b2b-a1b1-443c-9b7d-84e9bf4396ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11974b2b-a1b1-443c-9b7d-84e9bf4396ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11974b2b-a1b1-443c-9b7d-84e9bf4396ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   [ U N K ]   w e n t         a  t h o u s a n d  m i l e s       t o  \\\n",
              "0   0.028354  0.100813  0.284534         0.107489   0.066532  0.036349   \n",
              "\n",
              "        b e   h e r e         .  \n",
              "0  0.044139  0.040933  0.290856  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_tokens=[]\n",
        "a = torch.mean(outputs[-1][-1][:,:,0,:],1)[0][1:-1]\n",
        "for t in tokens:\n",
        "    new_tokens.append(tokenizer.convert_tokens_to_string(t))\n",
        "inf_df = pd.DataFrame([(a/torch.sum(a)).tolist()], columns=new_tokens[1:-1])\n",
        "inf_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "R4_yhWPkf_Jo",
        "outputId": "1b870091-9c66-44c5-fe29-12de65be1a07"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 792x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(len(tokens), 1))\n",
        "sns.heatmap(inf_df,cmap=sns.cm.rocket_r, cbar=False, annot=True, yticklabels=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAzGxgoNgTSa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "lmharness",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "035c7745ba774040834144e2b1cbaefc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21f279d04a24f30a9cdbb04567a1129",
            "placeholder": "​",
            "style": "IPY_MODEL_0d013aaf5cab48579ba671a633f2b723",
            "value": " 1.34G/1.34G [00:22&lt;00:00, 60.8MB/s]"
          }
        },
        "053fe08a58a1429cb10ab97c4b2492de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "079b0dd8be4848d78f8afb1308d43b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8edb39e2fce84d6ba6310db67996835a",
            "placeholder": "​",
            "style": "IPY_MODEL_979c7eae0b78482ba1ca5cc94fb0c4a9",
            "value": " 571/571 [00:00&lt;00:00, 13.8kB/s]"
          }
        },
        "0d013aaf5cab48579ba671a633f2b723": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fd0d958493e4bdcbab4f3d4a876c0c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2541d1bff8b94acc80c1b93a463588da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28c0c7a694894cc8abd55ad8b1644b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "318abcab4e1c4c90986b2c44ed7fafca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "352f7b0297e54ffb98d55402103c803c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35f607b3410b4f2685b9dd32199186fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fce6f4faae3a44d882f3a29a021f72e2",
            "placeholder": "​",
            "style": "IPY_MODEL_fc7371717a0641ce9454903980b15fc0",
            "value": "Downloading: 100%"
          }
        },
        "42cf76738723468c89bb91da3a286474": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43e03a0f43ba4b4b997c09d4a295ab82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b9c9d490dce43429307804fc91b3d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5596ef02038847429eeae270b0abd9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb811041a4b046429998521520cee351",
              "IPY_MODEL_edbd30c11faa4cf6b0d1782d732a0a48",
              "IPY_MODEL_a7a33d4939d245f28ede93b3057eac62"
            ],
            "layout": "IPY_MODEL_e14e2a2b0f99428091deff9b0a33025c"
          }
        },
        "618e0e1d878c4872888777280b3d7a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f50f07c7efd44282ae5e963725684dd2",
            "max": 1344997306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2541d1bff8b94acc80c1b93a463588da",
            "value": 1344997306
          }
        },
        "62855445029c4291b1ae47fba4b658d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710963428e544ce898264e8422434852": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77497eb681d24d579479125788ee99c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794024b537534aa6a83355bb14e69ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9c9d490dce43429307804fc91b3d4c",
            "placeholder": "​",
            "style": "IPY_MODEL_b5065294ebbf47bfa22566be004a1118",
            "value": "Downloading: 100%"
          }
        },
        "89f7e455c5e241f4bd3be6191c1cf79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e8f29311c444630944fee8548d27442": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8edb39e2fce84d6ba6310db67996835a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "979c7eae0b78482ba1ca5cc94fb0c4a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b396d871c9b4553a4cb0679641b4d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7a33d4939d245f28ede93b3057eac62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fd0d958493e4bdcbab4f3d4a876c0c8",
            "placeholder": "​",
            "style": "IPY_MODEL_9b396d871c9b4553a4cb0679641b4d7d",
            "value": " 466k/466k [00:00&lt;00:00, 531kB/s]"
          }
        },
        "aaa05385a09542a7ad5929fe040b55e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ace2e5b5e08e4051bf30acdb6d4e21c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af30ba2e6822481b938ee5e8a95abfe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcf2e0c8af444cac8f2da731c97c14d4",
              "IPY_MODEL_c8c187b8474144edb6d890292bd5df62",
              "IPY_MODEL_ed80d9d6b3604fbf985da258810e1283"
            ],
            "layout": "IPY_MODEL_cd99997b376243419de6640f43a8eadc"
          }
        },
        "b2e9706c53c343dea13953287f7f50b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5065294ebbf47bfa22566be004a1118": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6c35c937f0d44ed86735b3e1fd47a24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb728348a7a747fca6a449354ea43a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c09c0a7e8aab422e9736c5dd35f7b19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe9db4c1f3d0455781cbad971fd05294",
              "IPY_MODEL_618e0e1d878c4872888777280b3d7a79",
              "IPY_MODEL_035c7745ba774040834144e2b1cbaefc"
            ],
            "layout": "IPY_MODEL_b6c35c937f0d44ed86735b3e1fd47a24"
          }
        },
        "c8c187b8474144edb6d890292bd5df62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f67adb00c2024e63b764263909fb3a06",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd40a6b8a20c4638a65c8efd6139a5b9",
            "value": 28
          }
        },
        "cd40a6b8a20c4638a65c8efd6139a5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd99997b376243419de6640f43a8eadc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d624bbe8b12f4dc3b98321cf292b43f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc7fd42fd3ff44cc9baaf591664ae4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb728348a7a747fca6a449354ea43a1c",
            "placeholder": "​",
            "style": "IPY_MODEL_89f7e455c5e241f4bd3be6191c1cf79e",
            "value": " 232k/232k [00:00&lt;00:00, 629kB/s]"
          }
        },
        "de54939599c247b18b9f64f798ecb92d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35f607b3410b4f2685b9dd32199186fe",
              "IPY_MODEL_dfde771e9ea54b118c466848410ee0dd",
              "IPY_MODEL_079b0dd8be4848d78f8afb1308d43b40"
            ],
            "layout": "IPY_MODEL_053fe08a58a1429cb10ab97c4b2492de"
          }
        },
        "dfde771e9ea54b118c466848410ee0dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62855445029c4291b1ae47fba4b658d9",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28c0c7a694894cc8abd55ad8b1644b27",
            "value": 571
          }
        },
        "e000a0eb8b554a2c96c171a175935d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0f5d2114b38472f8972e991b27a51f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e14e2a2b0f99428091deff9b0a33025c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b06189106b44f083b6553d728e3d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_794024b537534aa6a83355bb14e69ac0",
              "IPY_MODEL_ec1d3996802247ab9a404a4a3afe88b3",
              "IPY_MODEL_dc7fd42fd3ff44cc9baaf591664ae4e5"
            ],
            "layout": "IPY_MODEL_d624bbe8b12f4dc3b98321cf292b43f3"
          }
        },
        "ec1d3996802247ab9a404a4a3afe88b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77497eb681d24d579479125788ee99c6",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_318abcab4e1c4c90986b2c44ed7fafca",
            "value": 231508
          }
        },
        "ed80d9d6b3604fbf985da258810e1283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42cf76738723468c89bb91da3a286474",
            "placeholder": "​",
            "style": "IPY_MODEL_43e03a0f43ba4b4b997c09d4a295ab82",
            "value": " 28.0/28.0 [00:00&lt;00:00, 722B/s]"
          }
        },
        "edbd30c11faa4cf6b0d1782d732a0a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e8f29311c444630944fee8548d27442",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_352f7b0297e54ffb98d55402103c803c",
            "value": 466062
          }
        },
        "f21f279d04a24f30a9cdbb04567a1129": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f50f07c7efd44282ae5e963725684dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f67adb00c2024e63b764263909fb3a06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb811041a4b046429998521520cee351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaa05385a09542a7ad5929fe040b55e0",
            "placeholder": "​",
            "style": "IPY_MODEL_e000a0eb8b554a2c96c171a175935d98",
            "value": "Downloading: 100%"
          }
        },
        "fc7371717a0641ce9454903980b15fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fce6f4faae3a44d882f3a29a021f72e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf2e0c8af444cac8f2da731c97c14d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ace2e5b5e08e4051bf30acdb6d4e21c9",
            "placeholder": "​",
            "style": "IPY_MODEL_b2e9706c53c343dea13953287f7f50b7",
            "value": "Downloading: 100%"
          }
        },
        "fe9db4c1f3d0455781cbad971fd05294": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_710963428e544ce898264e8422434852",
            "placeholder": "​",
            "style": "IPY_MODEL_e0f5d2114b38472f8972e991b27a51f1",
            "value": "Downloading: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
